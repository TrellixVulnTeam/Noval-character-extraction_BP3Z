{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLOps: End-to-End Hugging Face Transformers with the Hub & SageMaker Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Development Environment and Permissions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & Imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterFloat, ParameterString\n",
    "\n",
    "from sagemaker.lambda_helper import Lambda\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import CacheConfig, ProcessingStep\n",
    "\n",
    "from sagemaker.huggingface import HuggingFace, HuggingFaceModel\n",
    "import sagemaker.huggingface\n",
    "\n",
    "from sagemaker.inputs import TrainingInput, CreateModelInput\n",
    "from sagemaker.workflow.steps import TrainingStep, TransformStep\n",
    "\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.step_collections import CreateModelStep, RegisterModel\n",
    "\n",
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo,ConditionGreaterThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep, JsonGet\n",
    "\n",
    "from sagemaker.workflow.pipeline import Pipeline, PipelineExperimentConfig\n",
    "from sagemaker.workflow.execution_variables import ExecutionVariables\n",
    "\n",
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.s3 import S3Uploader,s3_path_join\n",
    "\n",
    "from sagemaker.transformer import Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Pipeline\n",
    "\n",
    "## 0. Pipeline parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::734836471744:role/service-role/AmazonSageMaker-ExecutionRole-20220512T110407\n",
      "sagemaker train data bucket: sagemaker-us-east-1-734836471744-stary\n",
      "train data location: s3://sagemaker-us-east-1-734836471744-stary/train.csv\n",
      "sagemaker bucket: sagemaker-us-east-1-734836471744\n",
      "sagemaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_traindata_bucket='sagemaker-us-east-1-734836471744-stary'\n",
    "\n",
    "# S3 prefix where every assets will be stored\n",
    "s3_prefix = \"stray-hugging-face-pipeline-demo\"\n",
    "\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session(default_bucket=sess.default_bucket())\n",
    "\n",
    "\n",
    "# s3 bucket used for storing assets and artifacts\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# aws region used\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# base name prefix for sagemaker jobs (training, processing, inference)\n",
    "base_job_prefix = s3_prefix\n",
    "\n",
    "# Cache configuration for workflow\n",
    "cache_config = CacheConfig(enable_caching=False, expire_after=\"30d\")\n",
    "\n",
    "\n",
    "# package versions\n",
    "_transformers_version = \"4.6\"\n",
    "_pytorch_version = \"1.7\"\n",
    "_py_version = \"py36\"\n",
    "\n",
    "\n",
    "train_bucket_path = \"s3://{}/\".format(sagemaker_traindata_bucket)\n",
    "\n",
    "\n",
    "train_input_data_uri =train_bucket_path+\"train.csv\"\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=train_input_data_uri,\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker train data bucket: {sagemaker_traindata_bucket}\")\n",
    "print(f\"train data location: {train_input_data_uri}\")\n",
    "print(f\"sagemaker bucket: {sagemaker_session.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sagemaker_session.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Processing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type_process_1=\"ml.c5.4xlarge\"\n",
    "instance_count_process_1= 1\n",
    "processing_instance_type = ParameterString(name=\"ProcessingInstanceType\", default_value=instance_type_process_1)\n",
    "processing_instance_count = ParameterInteger(name=\"ProcessingInstanceCount\", default_value=instance_count_process_1)\n",
    "processing_script = ParameterString(name=\"ProcessingScript\", default_value=\"./scripts/preprocessing.py\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "processing_output_destination = f\"s3://{bucket}/{s3_prefix}/data\"\n",
    "\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=\"0.23-1\",\n",
    "    instance_type=instance_type_process_1,\n",
    "    instance_count=instance_count_process_1,\n",
    "    base_job_name=base_job_prefix + \"/preprocessing\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"ProcessDataForTraining\",\n",
    "    cache_config=cache_config,\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train\",\n",
    "            source=\"/opt/ml/processing/train\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"train\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"validation\",\n",
    "            source=\"/opt/ml/processing/validation\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"validation\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"test\",\n",
    "            source=\"/opt/ml/processing/test\",\n",
    "            destination=Join(\n",
    "                on=\"/\",\n",
    "                values=[\n",
    "                    \"s3://{}\".format(bucket),\n",
    "                    s3_prefix,\n",
    "                    ExecutionVariables.PIPELINE_EXECUTION_ID,\n",
    "                    \"test\",\n",
    "                ],\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    code=\"./scripts/preprocessing.py\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training Step\n",
    "\n",
    "We use SageMaker's [Hugging Face](https://sagemaker.readthedocs.io/en/stable/frameworks/huggingface/sagemaker.huggingface.html) Estimator class to create a model training step for the Hugging Face [DistilBERT](https://huggingface.co/distilbert-base-uncased) model.  Transformer-based models such as the original BERT can be very large and slow to train.  DistilBERT, however, is a small, fast, cheap and light Transformer model trained by distilling BERT base. It reduces the size of a BERT model by 40%, while retaining 97% of its language understanding capabilities and being 60% faster. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hugging Face estimator also takes hyperparameters as a dictionary. The training instance type and size are pipeline parameters that can be easily varied in future pipeline runs without changing any code.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training step parameters\n",
    "entry_point_train = 'run_glue.py'\n",
    "source_dir_train = \"./scripts\"\n",
    "instance_type_train = 'ml.p3.2xlarge'\n",
    "instance_count_train = 1\n",
    "volume_size_train = 400\n",
    "train_batch_size_train = \"4\"\n",
    "eval_batch_size_train = \"4\"\n",
    "\n",
    "# pipeline hyperparameters, which are passed into the training job\n",
    "training_entry_point = ParameterString(name=\"TrainingEntryPoint\", default_value= entry_point_train)\n",
    "training_source_dir = ParameterString(name=\"TrainingSourceDir\", default_value=source_dir_train)\n",
    "training_instance_type = ParameterString(name=\"TrainingInstanceType\", default_value=instance_type_train)\n",
    "training_instance_count = ParameterInteger(name=\"TrainingInstanceCount\", default_value=instance_count_train)\n",
    "TrainBatchSize=ParameterString(name=\"per_device_train_batch_size\", default_value=train_batch_size_train)\n",
    "EvalBatchSize=ParameterString(name=\"per_device_eval_batch_size\", default_value=eval_batch_size_train)         \n",
    "Epochs=ParameterString(name=\"num_train_epochs\", default_value=\"5\")       \n",
    "learning_rate=ParameterString(name=\"LearningRate\", default_value=\"5e-5\")               \n",
    "fp16=ParameterString(name=\"Fp16\", default_value=\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/steps.py:321: UserWarning: Profiling is enabled on the provided estimator. The default profiler rule includes a timestamp which will change each time the pipeline is upserted, causing cache misses. If profiling is not needed, set disable_profiler to True on the estimator.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point=entry_point_train,\n",
    "    source_dir=source_dir_train,\n",
    "    base_job_name=base_job_prefix + \"/training\",\n",
    "    instance_type=instance_type_train,\n",
    "    instance_count=instance_count_train,\n",
    "    volume_size=volume_size_train,\n",
    "    role=role,\n",
    "    transformers_version=_transformers_version,\n",
    "    pytorch_version=_pytorch_version,\n",
    "    py_version=_py_version,\n",
    "    hyperparameters={'per_device_train_batch_size':train_batch_size_train,\n",
    "                     'per_device_eval_batch_size': eval_batch_size_train,\n",
    "                     'model_name_or_path': 'bert-base-uncased',\n",
    "                     'train_file':'/opt/ml/input/data/train/train.csv',\n",
    "                     'validation_file':'/opt/ml/input/data/validation/validation.csv',\n",
    "                     'test_file':'/opt/ml/input/data/test/test.csv',\n",
    "                     'do_train': True,\n",
    "                     'do_predict': True,\n",
    "                     'do_eval': True,\n",
    "                     'save_total_limit':3,\n",
    "                     'output_dir': '/opt/ml/model',\n",
    "                     'num_train_epochs': 5,\n",
    "                     'learning_rate': 5e-5,\n",
    "                     'seed': 7,\n",
    "                     'fp16': False,\n",
    "                     'eval_steps': 1000,\n",
    "                     },\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainHuggingFaceModel\",\n",
    "    estimator=huggingface_estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"test\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    },\n",
    "    cache_config=cache_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline definition and execution\n",
    "\n",
    "SageMaker Pipelines constructs the pipeline graph from the implicit definition created by the way pipeline steps inputs and outputs are specified.  There's no need to specify that a step is a \"parallel\" or \"serial\" step.  Steps such as model registration after the condition step are not listed in the pipeline definition because they do not run unless the condition is true.  If so, they are run in order based on their specified inputs and outputs.\n",
    "\n",
    "Each Parameter we defined holds a default value, which can be overwritten before starting the pipeline. [Parameter Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-parameters.html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overwriting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter which should be overwritten\n",
    "pipeline_parameters=dict(\n",
    "        ModelId=\"stary-base-uncased\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    name=f\"HuggingFaceDemoPipeline\",\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        processing_instance_type,\n",
    "        processing_instance_count,\n",
    "        processing_script,\n",
    "        training_entry_point,\n",
    "        training_source_dir,\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        Epochs,\n",
    "        TrainBatchSize,\n",
    "        EvalBatchSize,\n",
    "        learning_rate,\n",
    "        fp16\n",
    "        \n",
    "    ],\n",
    "    steps=[step_process,step_train],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine the pipeline definition in JSON format.  You also can inspect the pipeline graph in SageMaker Studio by going to the page for your pipeline.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Version': '2020-12-01',\n",
       " 'Metadata': {},\n",
       " 'Parameters': [{'Name': 'InputData',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 's3://sagemaker-us-east-1-734836471744-stary/train.csv'},\n",
       "  {'Name': 'ProcessingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.c5.4xlarge'},\n",
       "  {'Name': 'ProcessingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'ProcessingScript',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': './scripts/preprocessing.py'},\n",
       "  {'Name': 'TrainingEntryPoint',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'run_glue.py'},\n",
       "  {'Name': 'TrainingSourceDir', 'Type': 'String', 'DefaultValue': './scripts'},\n",
       "  {'Name': 'TrainingInstanceType',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': 'ml.p3.2xlarge'},\n",
       "  {'Name': 'TrainingInstanceCount', 'Type': 'Integer', 'DefaultValue': 1},\n",
       "  {'Name': 'num_train_epochs', 'Type': 'String', 'DefaultValue': '5'},\n",
       "  {'Name': 'per_device_train_batch_size',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': '4'},\n",
       "  {'Name': 'per_device_eval_batch_size',\n",
       "   'Type': 'String',\n",
       "   'DefaultValue': '4'},\n",
       "  {'Name': 'LearningRate', 'Type': 'String', 'DefaultValue': '5e-5'},\n",
       "  {'Name': 'Fp16', 'Type': 'String', 'DefaultValue': 'False'}],\n",
       " 'PipelineExperimentConfig': {'ExperimentName': {'Get': 'Execution.PipelineName'},\n",
       "  'TrialName': {'Get': 'Execution.PipelineExecutionId'}},\n",
       " 'Steps': [{'Name': 'ProcessDataForTraining',\n",
       "   'Type': 'Processing',\n",
       "   'Arguments': {'ProcessingResources': {'ClusterConfig': {'InstanceType': 'ml.c5.4xlarge',\n",
       "      'InstanceCount': 1,\n",
       "      'VolumeSizeInGB': 30}},\n",
       "    'AppSpecification': {'ImageUri': '683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3',\n",
       "     'ContainerEntrypoint': ['python3',\n",
       "      '/opt/ml/processing/input/code/preprocessing.py']},\n",
       "    'RoleArn': 'arn:aws:iam::734836471744:role/service-role/AmazonSageMaker-ExecutionRole-20220512T110407',\n",
       "    'ProcessingInputs': [{'InputName': 'input-1',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': {'Get': 'Parameters.InputData'},\n",
       "       'LocalPath': '/opt/ml/processing/input',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}},\n",
       "     {'InputName': 'code',\n",
       "      'AppManaged': False,\n",
       "      'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-734836471744/ProcessDataForTraining-2535c36df5fd1b396a23b55b5d65c48b/input/code/preprocessing.py',\n",
       "       'LocalPath': '/opt/ml/processing/input/code',\n",
       "       'S3DataType': 'S3Prefix',\n",
       "       'S3InputMode': 'File',\n",
       "       'S3DataDistributionType': 'FullyReplicated',\n",
       "       'S3CompressionType': 'None'}}],\n",
       "    'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'train',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3://sagemaker-us-east-1-734836471744',\n",
       "           'stray-hugging-face-pipeline-demo',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'train']}},\n",
       "        'LocalPath': '/opt/ml/processing/train',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'validation',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3://sagemaker-us-east-1-734836471744',\n",
       "           'stray-hugging-face-pipeline-demo',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'validation']}},\n",
       "        'LocalPath': '/opt/ml/processing/validation',\n",
       "        'S3UploadMode': 'EndOfJob'}},\n",
       "      {'OutputName': 'test',\n",
       "       'AppManaged': False,\n",
       "       'S3Output': {'S3Uri': {'Std:Join': {'On': '/',\n",
       "          'Values': ['s3://sagemaker-us-east-1-734836471744',\n",
       "           'stray-hugging-face-pipeline-demo',\n",
       "           {'Get': 'Execution.PipelineExecutionId'},\n",
       "           'test']}},\n",
       "        'LocalPath': '/opt/ml/processing/test',\n",
       "        'S3UploadMode': 'EndOfJob'}}]}},\n",
       "   'CacheConfig': {'Enabled': False, 'ExpireAfter': '30d'}},\n",
       "  {'Name': 'TrainHuggingFaceModel',\n",
       "   'Type': 'Training',\n",
       "   'Arguments': {'AlgorithmSpecification': {'TrainingInputMode': 'File',\n",
       "     'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-training:1.7-transformers4.6-gpu-py36-cu110-ubuntu18.04',\n",
       "     'EnableSageMakerMetricsTimeSeries': True},\n",
       "    'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-734836471744/'},\n",
       "    'StoppingCondition': {'MaxRuntimeInSeconds': 86400},\n",
       "    'ResourceConfig': {'InstanceCount': 1,\n",
       "     'InstanceType': 'ml.p3.2xlarge',\n",
       "     'VolumeSizeInGB': 400},\n",
       "    'RoleArn': 'arn:aws:iam::734836471744:role/service-role/AmazonSageMaker-ExecutionRole-20220512T110407',\n",
       "    'InputDataConfig': [{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.ProcessDataForTraining.ProcessingOutputConfig.Outputs['train'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'train'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.ProcessDataForTraining.ProcessingOutputConfig.Outputs['validation'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'validation'},\n",
       "     {'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix',\n",
       "        'S3Uri': {'Get': \"Steps.ProcessDataForTraining.ProcessingOutputConfig.Outputs['test'].S3Output.S3Uri\"},\n",
       "        'S3DataDistributionType': 'FullyReplicated'}},\n",
       "      'ContentType': 'text/csv',\n",
       "      'ChannelName': 'test'}],\n",
       "    'HyperParameters': {'per_device_train_batch_size': '\"4\"',\n",
       "     'per_device_eval_batch_size': '\"4\"',\n",
       "     'model_name_or_path': '\"bert-base-uncased\"',\n",
       "     'train_file': '\"/opt/ml/input/data/train/train.csv\"',\n",
       "     'validation_file': '\"/opt/ml/input/data/validation/validation.csv\"',\n",
       "     'test_file': '\"/opt/ml/input/data/test/test.csv\"',\n",
       "     'do_train': 'true',\n",
       "     'do_predict': 'true',\n",
       "     'do_eval': 'true',\n",
       "     'save_total_limit': '3',\n",
       "     'output_dir': '\"/opt/ml/model\"',\n",
       "     'num_train_epochs': '5',\n",
       "     'learning_rate': '5e-05',\n",
       "     'seed': '7',\n",
       "     'fp16': 'false',\n",
       "     'eval_steps': '1000',\n",
       "     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-734836471744/TrainHuggingFaceModel-25d4858898224a9cd405dee007ab3afc/source/sourcedir.tar.gz\"',\n",
       "     'sagemaker_program': '\"run_glue.py\"',\n",
       "     'sagemaker_container_log_level': '20',\n",
       "     'sagemaker_region': '\"us-east-1\"'},\n",
       "    'DebugHookConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-734836471744/',\n",
       "     'CollectionConfigurations': []},\n",
       "    'ProfilerRuleConfigurations': [{'RuleConfigurationName': 'ProfilerReport-1658717633',\n",
       "      'RuleEvaluatorImage': '503895931360.dkr.ecr.us-east-1.amazonaws.com/sagemaker-debugger-rules:latest',\n",
       "      'RuleParameters': {'rule_to_invoke': 'ProfilerReport'}}],\n",
       "    'ProfilerConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-734836471744/'}},\n",
       "   'CacheConfig': {'Enabled': False, 'ExpireAfter': '30d'}}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(pipeline.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](./imgs/pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`upsert` creates or updates the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineArn': 'arn:aws:sagemaker:us-east-1:734836471744:pipeline/huggingfacedemopipeline',\n",
       " 'ResponseMetadata': {'RequestId': '93f57a1a-a169-45b4-a267-3d5db11e481c',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '93f57a1a-a169-45b4-a267-3d5db11e481c',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '91',\n",
       "   'date': 'Mon, 25 Jul 2022 02:53:53 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "WaiterError",
     "evalue": "Waiter PipelineExecutionComplete failed: Max attempts exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWaiterError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-72be0c8b7085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, delay, max_attempts)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mwaiter_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         )\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPipelineExecutionArn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mWaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     wait.__doc__ = WaiterDocstring(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/waiter.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                     \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                     \u001b[0mlast_response\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 )\n\u001b[1;32m    393\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWaiterError\u001b[0m: Waiter PipelineExecutionComplete failed: Max attempts exceeded"
     ]
    }
   ],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Resources\n",
    "\n",
    "The following cell will delete the resources created by the Lambda function and the Lambda itself. \n",
    "Deleting other resources such as the S3 bucket and the IAM role for the Lambda function are the responsibility of the notebook user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
