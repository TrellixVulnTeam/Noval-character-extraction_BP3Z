{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e225a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a64596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::tqdm==4.62.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::black==21.11b1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.7.3=py38h497a2fe_1\n",
      "  - conda-forge/noarch::dask-core==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::pytest==6.2.5=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::watchdog==2.1.6=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::aiohttp==3.8.1=py38h497a2fe_0\n",
      "  - conda-forge/linux-64::astropy==5.0=py38h6c62de6_0\n",
      "  - conda-forge/linux-64::bokeh==2.4.2=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::distributed==2021.11.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::flask==2.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.0=py38hf4fb855_0\n",
      "  - conda-forge/noarch::nbformat==5.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.5.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::networkx==2.6.3=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::python-lsp-server==1.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nbconvert==6.3.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-black==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.26.0=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-client==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.11.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::cookiecutter==1.7.0=py_0\n",
      "  - conda-forge/noarch::jupyter_server==1.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.5.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pooch==1.5.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-project==0.10.2=pyhd8ed1ab_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::ipyparallel==8.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==6.4.6=pyha770c72_0\n",
      "  - conda-forge/linux-64::scikit-image==0.18.3=py38h43a58ef_0\n",
      "  - conda-forge/linux-64::nb_conda==2.2.1=py38h578d9bd_4\n",
      "  - conda-forge/noarch::nbclassic==0.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.5.2=py38h578d9bd_1\n",
      "  - conda-forge/noarch::ipywidgets==7.6.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==3.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py38h578d9bd_7\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::spyder==5.2.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.5=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - defaults/linux-64::_anaconda_depends==2021.11=py38_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::tqdm==4.62.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::black==21.11b1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda-package-handling==1.7.3=py38h497a2fe_1\n",
      "  - conda-forge/noarch::dask-core==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/linux-64::pytest==6.2.5=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::watchdog==2.1.6=py38h578d9bd_1\n",
      "  - conda-forge/linux-64::aiohttp==3.8.1=py38h497a2fe_0\n",
      "  - conda-forge/linux-64::astropy==5.0=py38h6c62de6_0\n",
      "  - conda-forge/linux-64::bokeh==2.4.2=py38h578d9bd_0\n",
      "  - conda-forge/linux-64::distributed==2021.11.2=py38h578d9bd_0\n",
      "  - conda-forge/noarch::flask==2.0.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.0=py38hf4fb855_0\n",
      "  - conda-forge/noarch::nbformat==5.1.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pylint==2.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::dask==2021.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclient==0.5.9=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::networkx==2.6.3=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::python-lsp-server==1.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nbconvert==6.3.0=py38h578d9bd_1\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-black==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.26.0=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-client==1.8.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::conda==4.11.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::cookiecutter==1.7.0=py_0\n",
      "  - conda-forge/noarch::jupyter_server==1.12.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.5.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::pooch==1.5.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::anaconda-project==0.10.2=pyhd8ed1ab_0\n",
      "  - defaults/noarch::conda-token==0.3.0=pyhd3eb1b0_0\n",
      "  - conda-forge/noarch::ipyparallel==8.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.8.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==6.4.6=pyha770c72_0\n",
      "  - conda-forge/linux-64::scikit-image==0.18.3=py38h43a58ef_0\n",
      "  - conda-forge/linux-64::nb_conda==2.2.1=py38h578d9bd_4\n",
      "  - conda-forge/noarch::nbclassic==0.3.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.5.2=py38h578d9bd_1\n",
      "  - conda-forge/noarch::ipywidgets==7.6.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==3.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py38h578d9bd_7\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::spyder==5.2.0=py38h578d9bd_0\n",
      "  - conda-forge/noarch::sphinxcontrib-serializinghtml==1.1.5=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - defaults/linux-64::_anaconda_depends==2021.11=py38_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.13.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - cudatoolkit=10.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2022.6.15  |       ha878542_0         149 KB  conda-forge\n",
      "    certifi-2022.6.15          |   py38h578d9bd_0         155 KB  conda-forge\n",
      "    colorama-0.4.5             |     pyhd8ed1ab_0          18 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |      h8c5a6a4_10       336.3 MB  conda-forge\n",
      "    dataclasses-0.8            |     pyhc8e2a94_3          10 KB  conda-forge\n",
      "    docutils-0.18.1            |   py38h578d9bd_1         737 KB  conda-forge\n",
      "    fsspec-2022.5.0            |     pyhd8ed1ab_0          96 KB  conda-forge\n",
      "    jsonschema-4.7.2           |     pyhd8ed1ab_0          63 KB  conda-forge\n",
      "    lxml-4.8.0                 |   py38h0a891b7_2         1.4 MB  conda-forge\n",
      "    openssl-1.1.1o             |       h166bdaf_0         2.1 MB  conda-forge\n",
      "    pillow-8.4.0               |   py38h8e6f84c_0         704 KB  conda-forge\n",
      "    pip-22.1.2                 |     pyhd8ed1ab_0         1.5 MB  conda-forge\n",
      "    pyyaml-6.0                 |   py38h0a891b7_4         182 KB  conda-forge\n",
      "    sphinx-5.0.2               |     pyh6c4a22f_0         1.5 MB  conda-forge\n",
      "    urllib3-1.26.10            |     pyhd8ed1ab_0         101 KB  conda-forge\n",
      "    websocket-client-1.3.3     |     pyhd8ed1ab_0          41 KB  conda-forge\n",
      "    werkzeug-2.1.2             |     pyhd8ed1ab_1         237 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       345.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  attrs              conda-forge/noarch::attrs-21.4.0-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.5-pyhd8ed1ab_0\n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-10.0.130-h8c5a6a4_10\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyhc8e2a94_3\n",
      "  docutils           conda-forge/linux-64::docutils-0.18.1-py38h578d9bd_1\n",
      "  fsspec             conda-forge/noarch::fsspec-2022.5.0-pyhd8ed1ab_0\n",
      "  jsonschema         conda-forge/noarch::jsonschema-4.7.2-pyhd8ed1ab_0\n",
      "  lxml               conda-forge/linux-64::lxml-4.8.0-py38h0a891b7_2\n",
      "  nltk               conda-forge/noarch::nltk-3.6.7-pyhd8ed1ab_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.4.0-py38h8e6f84c_0\n",
      "  pip                conda-forge/noarch::pip-22.1.2-pyhd8ed1ab_0\n",
      "  pyyaml             conda-forge/linux-64::pyyaml-6.0-py38h0a891b7_4\n",
      "  sphinx             conda-forge/noarch::sphinx-5.0.2-pyh6c4a22f_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.10-pyhd8ed1ab_0\n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.3.3-pyhd8ed1ab_0\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.1.2-pyhd8ed1ab_1\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2021.10.8-ha878542_0 --> 2022.6.15-ha878542_0\n",
      "  certifi                          2021.10.8-py38h578d9bd_1 --> 2022.6.15-py38h578d9bd_0\n",
      "  openssl                                 1.1.1l-h7f98852_0 --> 1.1.1o-h166bdaf_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "jsonschema-4.7.2     | 63 KB     | ##################################### | 100% \n",
      "pillow-8.4.0         | 704 KB    | ##################################### | 100% \n",
      "cudatoolkit-10.0.130 | 336.3 MB  | ##################################### | 100% \n",
      "ca-certificates-2022 | 149 KB    | ##################################### | 100% \n",
      "openssl-1.1.1o       | 2.1 MB    | ##################################### | 100% \n",
      "dataclasses-0.8      | 10 KB     | ##################################### | 100% \n",
      "werkzeug-2.1.2       | 237 KB    | ##################################### | 100% \n",
      "fsspec-2022.5.0      | 96 KB     | ##################################### | 100% \n",
      "lxml-4.8.0           | 1.4 MB    | ##################################### | 100% \n",
      "pip-22.1.2           | 1.5 MB    | ##################################### | 100% \n",
      "urllib3-1.26.10      | 101 KB    | ##################################### | 100% \n",
      "docutils-0.18.1      | 737 KB    | ##################################### | 100% \n",
      "certifi-2022.6.15    | 155 KB    | ##################################### | 100% \n",
      "websocket-client-1.3 | 41 KB     | ##################################### | 100% \n",
      "pyyaml-6.0           | 182 KB    | ##################################### | 100% \n",
      "sphinx-5.0.2         | 1.5 MB    | ##################################### | 100% \n",
      "colorama-0.4.5       | 18 KB     | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting git+https://github.com/allenai/longformer.git\n",
      "  Cloning https://github.com/allenai/longformer.git to /tmp/pip-req-build-unpzq232\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/allenai/longformer.git /tmp/pip-req-build-unpzq232\n",
      "  Resolved https://github.com/allenai/longformer.git to commit caefee668e39cacdece7dd603a0bebf24df6d8ca\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers\n",
      "  Cloning http://github.com/ibeltagy/transformers.git (to revision longformer_encoder_decoder) to /tmp/pip-install-cne4x9nh/transformers_8925d2f5a07642c7bc03d91d47a181c8\n",
      "  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/transformers.git /tmp/pip-install-cne4x9nh/transformers_8925d2f5a07642c7bc03d91d47a181c8\n",
      "  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n",
      "  Running command git checkout -b longformer_encoder_decoder --track origin/longformer_encoder_decoder\n",
      "  warning: redirecting to https://github.com/ibeltagy/transformers.git/\n",
      "  Switched to a new branch 'longformer_encoder_decoder'\n",
      "  Branch 'longformer_encoder_decoder' set up to track remote branch 'longformer_encoder_decoder' from 'origin'.\n",
      "  Resolved http://github.com/ibeltagy/transformers.git to commit 52d6236dc15ad5142b4146ff74d2ec973fa3da22\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning\n",
      "  Cloning http://github.com/ibeltagy/pytorch-lightning.git (to revision v0.8.5_fixes) to /tmp/pip-install-cne4x9nh/pytorch-lightning_9a8c24a5fd6c46c9a9d5370524cd7e26\n",
      "  Running command git clone --filter=blob:none --quiet http://github.com/ibeltagy/pytorch-lightning.git /tmp/pip-install-cne4x9nh/pytorch-lightning_9a8c24a5fd6c46c9a9d5370524cd7e26\n",
      "  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n",
      "  Running command git checkout -b v0.8.5_fixes --track origin/v0.8.5_fixes\n",
      "  warning: redirecting to https://github.com/ibeltagy/pytorch-lightning.git/\n",
      "  Switched to a new branch 'v0.8.5_fixes'\n",
      "  Branch 'v0.8.5_fixes' set up to track remote branch 'v0.8.5_fixes' from 'origin'.\n",
      "  Resolved http://github.com/ibeltagy/pytorch-lightning.git to commit 7ed5d849a0c76fa2199162f0283507e36601ded6\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from longformer==0.1) (1.12.0)\n",
      "Requirement already satisfied: tensorboardX in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from longformer==0.1) (2.5.1)\n",
      "Requirement already satisfied: test-tube==0.7.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from longformer==0.1) (0.7.5)\n",
      "Requirement already satisfied: nlp in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from longformer==0.1) (0.4.0)\n",
      "Requirement already satisfied: rouge_score in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from longformer==0.1) (0.0.4)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (1.20.3)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (1.3.4)\n",
      "Requirement already satisfied: tensorboard>=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (2.9.1)\n",
      "Requirement already satisfied: future in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from test-tube==0.7.5->longformer==0.1) (0.18.2)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from torch>=1.6.0->longformer==0.1) (4.0.0)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (3.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=0.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (7.0.0)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (0.3.4)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nlp->longformer==0.1) (3.4.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pytorch-lightning@ git+http://github.com/ibeltagy/pytorch-lightning.git@v0.8.5_fixes#egg=pytorch-lightning->longformer==0.1) (6.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from rouge_score->longformer==0.1) (1.16.0)\n",
      "Requirement already satisfied: absl-py in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from rouge_score->longformer==0.1) (1.2.0)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from rouge_score->longformer==0.1) (3.7)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboardX->longformer==0.1) (3.19.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.8.1rc2)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (2021.11.10)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.1.96)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (0.0.53)\n",
      "Requirement already satisfied: pillow in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from imageio>=2.3.0->test-tube==0.7.5->longformer==0.1) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas>=0.20.3->test-tube==0.7.5->longformer==0.1) (2021.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->nlp->longformer==0.1) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->nlp->longformer==0.1) (1.26.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->nlp->longformer==0.1) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->nlp->longformer==0.1) (2.0.8)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.47.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (59.4.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (2.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.37.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk->rouge_score->longformer==0.1) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from nltk->rouge_score->longformer==0.1) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging->transformers@ git+http://github.com/ibeltagy/transformers.git@longformer_encoder_decoder#egg=transformers->longformer==0.1) (3.0.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.15.0->test-tube==0.7.5->longformer==0.1) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!conda install cudatoolkit=10.0 -y\n",
    "!pip install git+https://github.com/allenai/longformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bc15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from longformer.longformer import Longformer, LongformerConfig\n",
    "from longformer.sliding_chunks import pad_to_window_size\n",
    "from transformers import RobertaTokenizer\n",
    "\n",
    "config = LongformerConfig.from_pretrained('longformer-base-4096/') \n",
    "# choose the attention mode 'n2', 'tvm' or 'sliding_chunks'\n",
    "# 'n2': for regular n2 attantion\n",
    "# 'tvm': a custom CUDA kernel implementation of our sliding window attention\n",
    "# 'sliding_chunks': a PyTorch implementation of our sliding window attention\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "\n",
    "model = Longformer.from_pretrained('longformer-base-4096/', config=config)\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "tokenizer.model_max_length = model.config.max_position_embeddings\n",
    "\n",
    "SAMPLE_TEXT = ' '.join(['Hello world! '] * 1000)  # long input document\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(SAMPLE_TEXT)).unsqueeze(0)  # batch of size 1\n",
    "\n",
    "# TVM code doesn't work on CPU. Uncomment this if `config.attention_mode = 'tvm'`\n",
    "# model = model.cuda(); input_ids = input_ids.cuda()\n",
    "\n",
    "# Attention mask values -- 0: no attention, 1: local attention, 2: global attention\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device) # initialize to local attention\n",
    "attention_mask[:, [1, 4, 21,]] =  2  # Set global attention based on the task. For example,\n",
    "                                     # classification: the <s> token\n",
    "                                     # QA: question tokens\n",
    "\n",
    "# padding seqlen to the nearest multiple of 512. Needed for the 'sliding_chunks' attention\n",
    "input_ids, attention_mask = pad_to_window_size(\n",
    "        input_ids, attention_mask, config.attention_window[0], tokenizer.pad_token_id)\n",
    "\n",
    "output = model(input_ids, attention_mask=attention_mask)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8536434b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (1.20.3)\n",
      "Requirement already satisfied: aiohttp in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (2.26.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (7.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc73602b",
   "metadata": {},
   "source": [
    "# prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8b29a0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a17e5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_file):\n",
    "    # Opening JSON file \n",
    "    f = open(json_file) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    content_ls = [' '.join(data['content'][str(i)]['word_list']) for i in range(len(data['content']))]\n",
    "    #label_ls = [data['content'][str(i)]['dialogue_label'] for i in range(len(data['content']))]\n",
    "    label_ls = [int(data['content'][str(i)]['ner_label'][0]) for i in range(len(data['content']))]\n",
    "    role_dict = data['role_id']\n",
    "    return content_ls,label_ls,role_dict\n",
    "\n",
    "def edit_b(x,role):\n",
    "    res = []\n",
    "    for i in range(len(x)):\n",
    "        res_str = \"center: \"+x[i] + \" roles: \"+str(list(role.values())) + \" paragraph: \" + ','.join(x)\n",
    "        res.append(res_str) \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1f32db1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load one book\n",
    "def load_book(book_path,tag):\n",
    "    chapter_ls = os.listdir(book_path)\n",
    "    cut=int(len(chapter_ls)*0.9)\n",
    "    if tag is True:\n",
    "        chapter_ls = chapter_ls[:cut]\n",
    "    else:\n",
    "        chapter_ls = chapter_ls[cut:]\n",
    "        \n",
    "    print (\"<<< books: \", chapter_ls)\n",
    "    res = []\n",
    "    for i in chapter_ls:\n",
    "        if i[-4:]==\"json\":\n",
    "            json_file = os.path.join(book_path,i)\n",
    "            content_ls, label_ls, role_dict = load_json(json_file)\n",
    "            content_ls = edit_b(content_ls,role_dict)\n",
    "            \n",
    "            df_res = pd.DataFrame({'sentence1_key':content_ls,'label':label_ls})\n",
    "            df_res = df_res[df_res['label']!=0]\n",
    "            df_res[\"label\"] = df_res[\"label\"].map(lambda x: role_dict[str(x)])\n",
    "            df_res[\"label\"] = df_res[\"label\"].map(lambda x: x+\" said the sentence\")\n",
    "\n",
    "            df_res['sentence1_key'] = df_res['sentence1_key'].map(lambda x: x.replace('“','\"'))\n",
    "            df_res['sentence1_key'] = df_res['sentence1_key'].map(lambda x: x.replace('”','\"'))\n",
    "            res.append(df_res)\n",
    "    res_table = pd.concat(res)\n",
    "\n",
    "    return res_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "507500b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< books:  [\"20%(2271377The Mafia's Good Wife)(1).json\", '80%(2059119Heart of Freeman).json', '60%_(2040244Lunar wolvesHis to own Book 1Complete).json', '30%_(2165912The Curse Of Violet Wraith).json', '60%_(2144894A Moonlit Encounter).json', '.ipynb_checkpoints', '20%_(1993322ASHER RICK).json', '20%_(2070697Revenge on my Ex-Husband).json', '60%_(2164082New Husband For My Wife) .json']\n",
      "<<< books:  ['80%(2192588love&mate) (1).json', '85%_(2061307His Ruthless Assistant (completed )).json']\n"
     ]
    }
   ],
   "source": [
    "book_path = 'stary/new_example_ten_json'\n",
    "train = load_book(book_path,True)\n",
    "test = load_book(book_path,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "92986a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['len'] = train['sentence1_key'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e19b6c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      1993.000000\n",
       "mean     102760.614150\n",
       "std       23012.371911\n",
       "min       62817.000000\n",
       "25%       68870.000000\n",
       "50%      117798.000000\n",
       "75%      122920.000000\n",
       "max      123295.000000\n",
       "Name: len, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6d9ec5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (2611, 3), test size(69, 2)\n"
     ]
    }
   ],
   "source": [
    "test1, test2 = train_test_split(test,test_size=0.1,random_state=0)\n",
    "train = pd.concat([train,test1])\n",
    "print (\"train size {}, test size{}\".format(train.shape,test2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa8faf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = \"stary/model_b_longdata\"\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "    print(\"The new directory is created!\")\n",
    "    \n",
    "train[[\"label\",\"sentence1_key\"]].to_csv('stary/model_b_longdata/train.csv',index=False,encoding='utf-8')\n",
    "test[[\"label\",\"sentence1_key\"]].to_csv('stary/model_b_longdata/test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ba1c6a",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fef1a573",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Background processes not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1721/2485218104.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nohup python -u longformer/scripts/summarization_opt.py --model_path \\'longformer-encdec-base-16384\\' --tokenizer \\'longformer-encdec-base-16384\\' --epochs 5 --max_input_len 10000  --batch_size 1 --dataset_name \"test\" --train_file \\'stary/model_b_longdata/train.csv\\' --test_file \\'stary/model_b_longdata/test.csv\\' --validation_file \\'stary/model_b_longdata/test.csv\\' > train0722.log 2>&1 &'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.8/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36msystem_piped\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;31m# os.system() or use ip.system=ip.system_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# if they really want a background process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Background processes not supported.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;31m# we explicitly do NOT return the subprocess status code, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Background processes not supported."
     ]
    }
   ],
   "source": [
    "python -u longformer/scripts/summarization_opt.py \\\n",
    "--model_path 'longformer-encdec-base-16384' \\\n",
    "--tokenizer 'longformer-encdec-base-16384' \\\n",
    "--epochs 5 \\\n",
    "--max_input_len 10000 \\\n",
    "--batch_size 1 \\\n",
    "--dataset_name \"test\" \\\n",
    "--train_file 'stary/model_b_longdata/train.csv' \\\n",
    "--test_file 'stary/model_b_longdata/test.csv' \\\n",
    "--validation_file 'stary/model_b_longdata/test.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019fc95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict   #导入此模块\n",
    "base_weights = torch.load(ckpt_pth)['state_dict']\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k, v in base_weights.items():\n",
    "    #print (k)\n",
    "    if k=='model.final_logits_bias':\n",
    "        new_state_dict['final_logits_bias'] = v \n",
    "        new_state_dict[k] = v \n",
    "    else:\n",
    "        new_state_dict[k] = v \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bb46f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from longformer import LongformerEncoderDecoderForConditionalGeneration, LongformerEncoderDecoderConfig\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#config = LongformerEncoderDecoderConfig.from_pretrained('/home/ec2-user/SageMaker/summarization/test/_ckpt_epoch_0_v0.ckpt')\n",
    "config = LongformerEncoderDecoderConfig.from_pretrained('longformer-encdec-base-16384')\n",
    "#config.attention_dropout = self.args.attention_dropout\n",
    "#config.gradient_checkpointing = self.args.grad_ckpt\n",
    "config.attention_mode = 'sliding_chunks'\n",
    "#config.attention_window = [self.args.attention_window] * config.encoder_layers\n",
    "\n",
    "model.model = LongformerEncoderDecoderForConditionalGeneration.from_pretrained('longformer-encdec-base-16384',config = config)\n",
    "#ckpt_pth = '/home/ec2-user/SageMaker/summarization/test/_ckpt_epoch_0_v2.ckpt'\n",
    "#x = torch.load(ckpt_pth)['state_dict']\n",
    "#x['model.model.final_logits_bias'] = x['model.final_logits_bias']\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "#model = torch.load(ckpt_pth,map_location=device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('longformer-encdec-base-16384')\n",
    "\n",
    "tokenizer.model_max_length = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d322a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SAMPLE_TEXT = ' '.join(['Hello world! '] * 200)  # long input document\n",
    "\n",
    "input_ids = torch.tensor(tokenizer.encode(SAMPLE_TEXT)).unsqueeze(0)\n",
    "\n",
    "attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "attention_mask[input_ids == tokenizer.pad_token_id] = 0\n",
    "attention_mask[:, 0] = 2 \n",
    "half_padding_mod = model.config.attention_window[0]\n",
    "input_ids, attention_mask = pad_to_window_size(  # ideally, should be moved inside the LongformerModel\n",
    "                input_ids, attention_mask, half_padding_mod, tokenizer.pad_token_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e76c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids =  model.model.generate(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                            use_cache=True, max_length=256,\n",
    "                                            num_beams=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aebe5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_str = tokenizer.batch_decode(generated_ids.tolist(), skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9f800d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bro said the sentence']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
