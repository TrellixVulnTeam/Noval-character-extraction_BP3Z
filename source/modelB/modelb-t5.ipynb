{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649fd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33145e",
   "metadata": {},
   "source": [
    "# data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9bcfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_file):\n",
    "    # Opening JSON file \n",
    "    f = open(json_file) \n",
    "\n",
    "    # returns JSON object as  \n",
    "    # a dictionary \n",
    "    data = json.load(f) \n",
    "    content_ls = [' '.join(data['content'][str(i)]['word_list']) for i in range(len(data['content']))]\n",
    "    #label_ls = [data['content'][str(i)]['dialogue_label'] for i in range(len(data['content']))]\n",
    "    label_ls = [int(data['content'][str(i)]['ner_label'][0]) for i in range(len(data['content']))]\n",
    "    role_dict = data['role_id']\n",
    "    return content_ls,label_ls,role_dict\n",
    "\n",
    "def edit_b(x,role):\n",
    "    res = []\n",
    "    for i in range(len(x)):\n",
    "        if i<3:\n",
    "            res_str = \"prefix: \"+','.join(x[:i])+\" center: \"+x[i] + \" after: \"+ ','.join(x[i:i+2]) + \" roles: \"+str(list(role.values()))\n",
    "            res.append(res_str) \n",
    "        elif len(x)-i<3:\n",
    "            res_str = \"prefix: \"+','.join(x[i-2:i])+\" center: \"+x[i] + \" after: \"+ ','.join(x[i:])+\" roles: \"+str(list(role.values()))\n",
    "            res.append(res_str)\n",
    "        else:\n",
    "            res_str = \"prefix: \"+','.join(x[i-2:i])+\" center: \"+x[i] + \" after: \"+ ','.join(x[i:i+2])+\" roles: \"+str(list(role.values()))\n",
    "            res.append(res_str)\n",
    "    return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8470f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load one book\n",
    "def load_book(book_path,tag):\n",
    "    chapter_ls = os.listdir(book_path)\n",
    "    cut=int(len(chapter_ls)*0.9)\n",
    "    if tag is True:\n",
    "        chapter_ls = chapter_ls[:cut]\n",
    "    else:\n",
    "        chapter_ls = chapter_ls[cut:]\n",
    "        \n",
    "    print (\"<<< books: \", chapter_ls)\n",
    "    res = []\n",
    "    for i in chapter_ls:\n",
    "        if i[-4:]==\"json\":\n",
    "            json_file = os.path.join(book_path,i)\n",
    "            content_ls, label_ls, role_dict = load_json(json_file)\n",
    "            content_ls = edit_b(content_ls,role_dict)\n",
    "            \n",
    "            df_res = pd.DataFrame({'sentence1_key':content_ls,'label':label_ls})\n",
    "            df_res = df_res[df_res['label']!=0]\n",
    "            df_res[\"label\"] = df_res[\"label\"].map(lambda x: role_dict[str(x)])\n",
    "            df_res[\"label\"] = df_res[\"label\"].map(lambda x: x+\" said the sentence\")\n",
    "\n",
    "            df_res['sentence1_key'] = df_res['sentence1_key'].map(lambda x: x.replace('“','\"'))\n",
    "            df_res['sentence1_key'] = df_res['sentence1_key'].map(lambda x: x.replace('”','\"'))\n",
    "            res.append(df_res)\n",
    "    res_table = pd.concat(res)\n",
    "\n",
    "    return res_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "096baf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<< books:  ['60%_(2040244Lunar wolvesHis to own Book 1Complete).json', \"20%(2271377The Mafia's Good Wife)(1).json\", '80%(2059119Heart of Freeman).json', '85%_(2061307His Ruthless Assistant (completed )).json', '60%_(2164082New Husband For My Wife) .json', '30%_(2165912The Curse Of Violet Wraith).json', '80%(2192588love&mate) (1).json', '60%_(2144894A Moonlit Encounter).json', '20%_(1993322ASHER RICK).json']\n",
      "<<< books:  ['20%_(2070697Revenge on my Ex-Husband).json']\n"
     ]
    }
   ],
   "source": [
    "book_path = '../modelA/new_example_ten_json'\n",
    "train = load_book(book_path,True)\n",
    "test = load_book(book_path,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8abf467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (2652, 2), test size(28, 2)\n"
     ]
    }
   ],
   "source": [
    "test1, test2 = train_test_split(test,test_size=0.25,random_state=0)\n",
    "train = pd.concat([train,test1])\n",
    "print (\"train size {}, test size{}\".format(train.shape,test2.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9bcd9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1_key</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>prefix: realized, that I had to pay attention ...</td>\n",
       "      <td>Aubrey said the sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>prefix: She is supposed to be here for me on t...</td>\n",
       "      <td>Aubrey said the sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>prefix: She was a woman in her mid-forties. Sh...</td>\n",
       "      <td>Aubrey said the sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>prefix: My dad offered to drive me to the airp...</td>\n",
       "      <td>Aubrey said the sentence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>prefix: \"Really?\",\"Yes,\" center: \"Victoria, st...</td>\n",
       "      <td>Eli said the sentence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence1_key  \\\n",
       "182  prefix: realized, that I had to pay attention ...   \n",
       "23   prefix: She is supposed to be here for me on t...   \n",
       "283  prefix: She was a woman in her mid-forties. Sh...   \n",
       "479  prefix: My dad offered to drive me to the airp...   \n",
       "639  prefix: \"Really?\",\"Yes,\" center: \"Victoria, st...   \n",
       "\n",
       "                        label  \n",
       "182  Aubrey said the sentence  \n",
       "23   Aubrey said the sentence  \n",
       "283  Aubrey said the sentence  \n",
       "479  Aubrey said the sentence  \n",
       "639     Eli said the sentence  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8beb4d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new directory is created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = '../model_b_data'\n",
    "\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "    print(\"The new directory is created!\")\n",
    "    \n",
    "train[[\"label\",\"sentence1_key\"]].to_csv('../model_b_data/train.csv',index=False,encoding='utf-8')\n",
    "test[[\"label\",\"sentence1_key\"]].to_csv('../model_b_data/test.csv',index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb7414",
   "metadata": {},
   "source": [
    "# train - model b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea7863d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "prefix='stary-datalab-modelb'\n",
    "\n",
    "bucket = sess.default_bucket() \n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"train/train.csv\")\n",
    ").upload_file(\"../model_b_data/train.csv\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(prefix, \"test/test.csv\")\n",
    ").upload_file(\"../model_b_data/test.csv\")\n",
    "\n",
    "training_input_path = f's3://{sess.default_bucket()}/{prefix}/train/train.csv'\n",
    "test_input_path = f's3://{sess.default_bucket()}/{prefix}/test/test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec3fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-26 02:56:26 Starting - Starting the training job...\n",
      "2022-07-26 02:56:54 Starting - Preparing the instances for trainingProfilerReport-1658804186: InProgress\n",
      ".........\n",
      "2022-07-26 02:58:23 Downloading - Downloading input data\n",
      "2022-07-26 02:58:23 Training - Downloading the training image............"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "from sagemaker.huggingface import TrainingCompilerConfig\n",
    "\n",
    "#speed up use sagemaker compiler https://towardsdatascience.com/speed-up-hugging-face-training-jobs-on-aws-by-up-to-50-with-sagemaker-training-compiler-9ad2ac5b0eb\n",
    "\n",
    "# hyperparameters which are passed to the training job\n",
    "hyperparameters={'reference_column':'sentence1_key',\n",
    "                 'hypothesis_column':'label',\n",
    "                 'train_file':'/opt/ml/input/data/train/train.csv',\n",
    "                 'validation_file':'/opt/ml/input/data/validation/test.csv',\n",
    "                 'test_file':'/opt/ml/input/data/test/test.csv',\n",
    "                 'output_dir':'/opt/ml/model',\n",
    "                 'do_train':True,\n",
    "                 'do_eval':True,\n",
    "                 'max_source_length': 128,\n",
    "                 'max_target_length': 128,\n",
    "                 'model_name_or_path': 't5-base',\n",
    "                 'learning_rate': 3e-4,\n",
    "                 'num_train_epochs': 1,\n",
    "                 'per_device_train_batch_size': 2,#16\n",
    "                 'gradient_accumulation_steps':2, \n",
    "                 'save_strategy':'steps',\n",
    "                 'evaluation_strategy':'epoch',\n",
    "                 'save_total_limit':1,\n",
    "                 'eval_steps':5000,\n",
    "                 'predict_with_generate':True # customerized accuracy\n",
    "                 }\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "        entry_point='run_train.py',\n",
    "        source_dir='./scripts',\n",
    "        instance_type='ml.p3.2xlarge',#'ml.p3dn.24xlarge'\n",
    "        instance_count=1,\n",
    "        role=role,\n",
    "        max_run=24*60*60,\n",
    "        transformers_version='4.6',\n",
    "        pytorch_version='1.7',\n",
    "        py_version='py36',\n",
    "        volume_size=128,\n",
    "        #compiler_config=TrainingCompilerConfig(),\n",
    "        base_job_name='train-modelb-stary-1epoch',\n",
    "        hyperparameters = hyperparameters,\n",
    "#         distribution=distribution\n",
    ")\n",
    "\n",
    "huggingface_estimator.fit({'train':training_input_path,'test':test_input_path,'validation': test_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f0cd40",
   "metadata": {},
   "source": [
    "# deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "add2659e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=\"s3://sagemaker-us-east-1-726335585155/train-modelb-stary-0713-crossbook-2022-07-14-06-27-10-862/output/model.tar.gz\",  # path to your trained sagemaker model\n",
    "   role=role, # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.6\", # transformers version used\n",
    "   pytorch_version=\"1.7\", # pytorch version used\n",
    "   py_version=\"py36\", # python version of the DLC\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a407506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "predictor = huggingface_model.deploy(\n",
    "   initial_instance_count=1,\n",
    "   instance_type=\"ml.g4dn.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d069d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 ms, sys: 0 ns, total: 13.3 ms\n",
      "Wall time: 864 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Annie said the sentence'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# example request, you always need to define \"inputs\"\n",
    "import time\n",
    "\n",
    "\n",
    "data = {\n",
    "   \"inputs\": 'prefix: \"Whatever. Chris has a heir to the pack now.\" She says.,\"Um last time I remembered in the laws it was clearly written that the offspring of the  Alpha can only take over if he is the son of the Alpha and the Luna and clearly after today no one will take this mistake,\" I point to her stomach , center: \"seriously again as you are just a mistress not the mate.\" I say putting a lot of emphasis on the word \\'mistress\\' as if it is the world\\'s most disgusting word. after: \"seriously again as you are just a mistress not the mate.\" I say putting a lot of emphasis on the word \\'mistress\\' as if it is the world\\'s most disgusting word.,\"Well at least he loves me.\" She says desperately. roles: [\\'Skylar\\', \\'Logan\\']'\n",
    "}\n",
    "\n",
    "# request\n",
    "predictor.predict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b3dce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../model_b_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d28b2b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for i in df['sentence1_key']:\n",
    "    data = {\"inputs\": i}\n",
    "\n",
    "    # request\n",
    "    res.append(predictor.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7973099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Annie said the sentence       0.96      0.99      0.97       211\n",
      "  Ava said the sentence       0.96      0.99      0.97       210\n",
      " Kade said the sentence       0.97      0.93      0.95       120\n",
      " Zach said the sentence       0.98      0.95      0.96       146\n",
      "\n",
      "               accuracy                           0.97       687\n",
      "              macro avg       0.97      0.96      0.96       687\n",
      "           weighted avg       0.97      0.97      0.97       687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#p f r\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = [i[0]['generated_text'] for i in res]\n",
    "y_true = df['label']\n",
    " \n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ab8ba86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prefix: \"Whatever. Chris has a heir to the pack now.\" She says.,\"Um last time I remembered in the laws it was clearly written that the offspring of the  Alpha can only take over if he is the son of the Alpha and the Luna and clearly after today no one will take this mistake,\" I point to her stomach , center: \"seriously again as you are just a mistress not the mate.\" I say putting a lot of emphasis on the word \\'mistress\\' as if it is the world\\'s most disgusting word. after: \"seriously again as you are just a mistress not the mate.\" I say putting a lot of emphasis on the word \\'mistress\\' as if it is the world\\'s most disgusting word.,\"Well at least he loves me.\" She says desperately. roles: [\\'Skylar\\', \\'Logan\\']'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence1_key'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f173c1aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Logan said the sentence'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87db21f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i]==y_pred[i]:\n",
    "        x = x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "67f3611b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bee705ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Who do you think I am? Of course I want it.\" She whispers and look at her stomach. '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence1_key'][362]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6568a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"What do you mean by that?\" She asks me surprised. '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentence1_key'][370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0b07d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
